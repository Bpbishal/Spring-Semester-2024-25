{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd7r4GQlpKMp",
        "outputId": "95b44084-1113-411b-bf1c-158c264140cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:07<00:00, 22.5MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 191MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1:\n",
            "FID: 10632.96 | Attack Success: 0.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6:\n",
            "FID: 16036.78 | Attack Success: 0.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11:\n",
            "FID: 10956.68 | Attack Success: 0.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16:\n",
            "FID: 13331.34 | Attack Success: 0.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 21:\n",
            "FID: 11709.27 | Attack Success: 0.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 26:\n",
            "FID: 14220.30 | Attack Success: 0.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 31:\n",
            "FID: 15596.25 | Attack Success: 0.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 36:\n",
            "FID: 16567.50 | Attack Success: 1.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 41:\n",
            "FID: 14926.65 | Attack Success: 0.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 46:\n",
            "FID: 16451.21 | Attack Success: 1.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 51:\n",
            "FID: 16274.94 | Attack Success: 2.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 56:\n",
            "FID: 16063.77 | Attack Success: 7.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 61:\n",
            "FID: 15328.15 | Attack Success: 15.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 66:\n",
            "FID: 13961.23 | Attack Success: 17.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 71:\n",
            "FID: 18245.22 | Attack Success: 25.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 76:\n",
            "FID: 17375.49 | Attack Success: 27.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 81:\n",
            "FID: 12786.17 | Attack Success: 29.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 86:\n",
            "FID: 12577.43 | Attack Success: 21.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 91:\n",
            "FID: 12154.69 | Attack Success: 23.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 96:\n",
            "FID: 15210.74 | Attack Success: 27.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.linalg import sqrtm\n",
        "from torchvision.models import inception_v3, Inception_V3_Weights, resnet18, ResNet18_Weights\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Configuration\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DATASET = \"cifar10\"  # \"mnist\" or \"cifar10\"\n",
        "LATENT_DIM = 128\n",
        "IMG_SIZE = 32  # Inception v3 requires 299x299\n",
        "CHANNELS = 3  # Force 3 channels for all datasets\n",
        "BATCH_SIZE = 1024\n",
        "EPOCHS = 100\n",
        "EPSILON = 0.1\n",
        "LR = 2e-4\n",
        "METRIC_FREQ = 5\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "os.makedirs(\"metrics\", exist_ok=True)\n",
        "\n",
        "# Data Loading with MNIST->RGB conversion\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*CHANNELS, [0.5]*CHANNELS)\n",
        "])\n",
        "\n",
        "if DATASET == \"cifar10\":\n",
        "    dataset = datasets.CIFAR10(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "elif DATASET == \"mnist\":\n",
        "    dataset = datasets.MNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "            transforms.Grayscale(num_output_channels=3),  # Convert to 3 channels\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "        ])\n",
        "    )\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "\n",
        "# Model Architectures\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(LATENT_DIM, 512 * 4 * 4),\n",
        "            nn.Unflatten(1, (512, 4, 4)),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, CHANNELS, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.net(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(CHANNELS, 64, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.AdaptiveAvgPool2d((4, 4)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512*4*4, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.net(img)\n",
        "\n",
        "class Attacker(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(CHANNELS, 32, 3, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, CHANNELS, 3, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x) * EPSILON\n",
        "\n",
        "# Initialize models\n",
        "generator = Generator().to(DEVICE)\n",
        "discriminator = Discriminator().to(DEVICE)\n",
        "attacker = Attacker().to(DEVICE)\n",
        "\n",
        "# Optimizers\n",
        "opt_G = optim.Adam(generator.parameters(), lr=LR, betas=(0.5, 0.999))\n",
        "opt_D = optim.Adam(discriminator.parameters(), lr=LR, betas=(0.5, 0.999))\n",
        "opt_A = optim.Adam(attacker.parameters(), lr=LR, betas=(0.5, 0.999))\n",
        "\n",
        "# AMP Scaler\n",
        "scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "# Metrics setup\n",
        "inception_model = resnet18(weights=ResNet18_Weights).to(DEVICE)\n",
        "inception_model.aux_logits = False\n",
        "inception_model.eval()\n",
        "\n",
        "def calculate_fid(real_imgs, fake_imgs, batch_size=100):\n",
        "    \"\"\"Calculate Frechet Inception Distance\"\"\"\n",
        "    # Normalize to [0,1]\n",
        "    real_imgs = (real_imgs + 1) * 0.5\n",
        "    fake_imgs = (fake_imgs + 1) * 0.5\n",
        "\n",
        "    # Normalize with Inception v3 stats\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "    real_imgs = (real_imgs - mean) / std\n",
        "    fake_imgs = (fake_imgs - mean) / std\n",
        "\n",
        "    real_features, fake_features = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Process real images\n",
        "        for i in range(0, len(real_imgs), batch_size):\n",
        "            batch = real_imgs[i:i+batch_size]\n",
        "            features = inception_model(batch)\n",
        "            real_features.append(features.cpu().numpy())\n",
        "\n",
        "        # Process fake images\n",
        "        for i in range(0, len(fake_imgs), batch_size):\n",
        "            batch = fake_imgs[i:i+batch_size]\n",
        "            features = inception_model(batch)\n",
        "            fake_features.append(features.cpu().numpy())\n",
        "\n",
        "    # Calculate statistics\n",
        "    real_features = np.concatenate(real_features, axis=0)\n",
        "    fake_features = np.concatenate(fake_features, axis=0)\n",
        "\n",
        "    mu_real, sigma_real = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n",
        "    mu_fake, sigma_fake = np.mean(fake_features, axis=0), np.cov(fake_features, rowvar=False)\n",
        "\n",
        "    # FID calculation\n",
        "    ssdiff = np.sum((mu_real - mu_fake)**2)\n",
        "    covmean = sqrtm(sigma_real.dot(sigma_fake))\n",
        "    fid = ssdiff + np.trace(sigma_real + sigma_fake - 2*covmean.real)\n",
        "\n",
        "    return fid\n",
        "\n",
        "def pgd_attack(model, images, epsilon=0.1, alpha=0.01, iters=10):\n",
        "    \"\"\"PGD attack validation\"\"\"\n",
        "    orig_images = images.detach().clone()\n",
        "    delta = torch.zeros_like(images).uniform_(-epsilon, epsilon)\n",
        "\n",
        "    for _ in range(iters):\n",
        "        delta.requires_grad = True\n",
        "        outputs = model(orig_images + delta)\n",
        "        loss = -torch.mean(outputs)\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        data_grad = delta.grad.detach()\n",
        "        delta = delta.detach() + alpha * data_grad.sign()\n",
        "        delta = torch.clamp(delta, -epsilon, epsilon)\n",
        "        delta = torch.clamp(orig_images + delta, -1, 1) - orig_images\n",
        "\n",
        "    return orig_images + delta\n",
        "\n",
        "def save_samples(epoch, generator, n_samples=100):\n",
        "    \"\"\"Save generated images\"\"\"\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(n_samples, LATENT_DIM, device=DEVICE)\n",
        "        gen_imgs = generator(z)\n",
        "        gen_imgs = gen_imgs * 0.5 + 0.5  # Denormalize\n",
        "        save_image(gen_imgs, f\"images/epoch_{epoch+1}.png\", nrow=10)\n",
        "\n",
        "# Precompute real samples for FID\n",
        "real_samples = torch.stack([dataset[i][0] for i in range(5000)]).to(DEVICE)\n",
        "metrics = {'fid': [], 'attack_success': []}\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "    attacker.train()\n",
        "\n",
        "    loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
        "    for real_imgs, _ in loop:\n",
        "        real_imgs = real_imgs.to(DEVICE)\n",
        "        batch_size = real_imgs.size(0)\n",
        "\n",
        "        # Train Attacker\n",
        "        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
        "            z = torch.randn(batch_size, LATENT_DIM, device=DEVICE)\n",
        "            fake_imgs = generator(z)\n",
        "            pert_real = attacker(real_imgs)\n",
        "            pert_fake = attacker(fake_imgs.detach())\n",
        "\n",
        "            d_real = discriminator(real_imgs + pert_real)\n",
        "            d_fake = discriminator(fake_imgs + pert_fake)\n",
        "            loss_A = -(torch.log(d_real).mean() + torch.log(1 - d_fake).mean())\n",
        "\n",
        "        opt_A.zero_grad()\n",
        "        scaler.scale(loss_A).backward()\n",
        "        scaler.step(opt_A)\n",
        "\n",
        "        # Train Discriminator\n",
        "        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
        "            z = torch.randn(batch_size, LATENT_DIM, device=DEVICE)\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pert_real = attacker(real_imgs)\n",
        "                pert_fake = attacker(fake_imgs)\n",
        "\n",
        "            d_real = discriminator(real_imgs + pert_real)\n",
        "            d_fake = discriminator(fake_imgs + pert_fake)\n",
        "            loss_D = -(torch.log(d_real).mean() + torch.log(1 - d_fake).mean())\n",
        "\n",
        "        opt_D.zero_grad()\n",
        "        scaler.scale(loss_D).backward()\n",
        "        scaler.step(opt_D)\n",
        "\n",
        "        # Train Generator\n",
        "        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
        "            z = torch.randn(batch_size, LATENT_DIM, device=DEVICE)\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pert_fake = attacker(fake_imgs)\n",
        "\n",
        "            d_fake = discriminator(fake_imgs + pert_fake)\n",
        "            loss_G = -torch.log(d_fake).mean()\n",
        "\n",
        "        opt_G.zero_grad()\n",
        "        scaler.scale(loss_G).backward()\n",
        "        scaler.step(opt_G)\n",
        "\n",
        "        scaler.update()\n",
        "        loop.set_postfix({\n",
        "            'D': f\"{loss_D.item():.4f}\",\n",
        "            'G': f\"{loss_G.item():.4f}\",\n",
        "            'A': f\"{loss_A.item():.4f}\"\n",
        "        })\n",
        "\n",
        "    # Validation and metrics\n",
        "    if epoch % METRIC_FREQ == 0:\n",
        "        generator.eval()\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(5000, LATENT_DIM, device=DEVICE)\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "        # Calculate FID\n",
        "        fid_score = calculate_fid(real_samples, fake_imgs)\n",
        "        metrics['fid'].append(fid_score)\n",
        "\n",
        "        # Attack validation\n",
        "        test_loader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
        "        real_batch, _ = next(iter(test_loader))\n",
        "        real_batch = real_batch.to(DEVICE)\n",
        "        adv_real = pgd_attack(discriminator, real_batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_real = discriminator(adv_real).cpu().numpy()\n",
        "\n",
        "        attack_success = 1 - accuracy_score(np.ones(100), (pred_real > 0.5).astype(int))\n",
        "        metrics['attack_success'].append(attack_success)\n",
        "\n",
        "        # Save progress\n",
        "        np.save(\"metrics/metrics.npy\", metrics)\n",
        "        save_samples(epoch, generator)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}:\")\n",
        "        print(f\"FID: {fid_score:.2f} | Attack Success: {attack_success*100:.1f}%\")\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vNOjqF1Ip5AI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}